{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Collecting Dataframes\n",
    "This notebook collects the various intermediate results (FOOOF, structural, and gene data, etc) and compiles them into corresponding dataframes, for both the macaque and human MNI data, separately, to be analyzed/visualized in subsequent notebooks. The human working memory ECoG data is not pre-computed or compiled here, and lives in ./4b_analysis_human_wm\n",
    "\n",
    "The last section describes how ECoG data is projected from MNI space to HCP-MMP via Gaussian smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "WARNING: Imported VTK version (8.1) does not match the one used\n",
      "         to build the TVTK classes (8.2). This may cause problems.\n",
      "         Please rebuild TVTK.\n",
      "********************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import io\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import nibabel as nib\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "sys.path.append('../')\n",
    "import echo_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global parameters for which fooof results to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# collect FOOOF results that were produced under these parameters\n",
    "win_len, p_cur = '1sec', 'psd_med'\n",
    "fg_param_to_load = 'knee'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Macaque ECoG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# get cortex files for electrode coordinates\n",
    "chibi_ctx_file = '/Users/rdgao/Documents/data/NeuroTycho/Propofol/GridLocations/20110621KTMD_Anesthesia+and+Sleep_Chibi_Toru+Yanagawa_mat_2Dimg/ChibiMap.mat'\n",
    "george_ctx_file = '/Users/rdgao/Documents/data/NeuroTycho/Propofol/GridLocations/20110112KTMD_Anesthesia+and+Sleep_George_Toru+Yanagawa_mat_2Dimg/GeorgeMap.mat'\n",
    "ctx_loc = []\n",
    "for ind, ctx_file in enumerate([chibi_ctx_file, george_ctx_file]):\n",
    "    ctx_mat = io.loadmat(ctx_file, squeeze_me=True)\n",
    "    ctx_loc.append(np.array([ctx_mat['X'], ctx_mat['Y']]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../echo_utils.py:59: RuntimeWarning: invalid value encountered in power\n",
      "  knee_freq = knee**(1./exponent)\n"
     ]
    }
   ],
   "source": [
    "# collection\n",
    "df_savepath = '../data/df_macaque'\n",
    "df_combined = pd.DataFrame()\n",
    "col_names = ['patient','cond','pharm', 'session_id', 'chan', 'exp', 'knee', 'tau','log_tau','err', 'r2']\n",
    "\n",
    "# load fooof results\n",
    "result_basepath = '/Users/rdgao/Documents/code/research/field-echos/results/neurotycho/rest_anes/'\n",
    "session_resultpath = np.sort([f+'/' for f in os.listdir(result_basepath) if os.path.isdir(result_basepath+f)])\n",
    "session_dict = {id:ind for ind, id in enumerate(np.unique([s.split('_')[3] for s in session_resultpath]))}\n",
    "\n",
    "for s in session_resultpath:\n",
    "    fooof_folder = result_basepath + s +'/psd/'+win_len+'/fooof/'+p_cur+'/'    \n",
    "    ff_list = [ff for ff in os.listdir(fooof_folder) if '.json' in ff]\n",
    "    ff_file = ff_list[np.where([fg_param_to_load in f for f in ff_list])[0][0]] # load specific fooof file\n",
    "    \n",
    "    # return fooof fits and convert knee to tau\n",
    "    fg_aps, fg_pks, fg_err, fg_r2s = echo_utils.return_fg_fits(ff_file, fooof_folder)\n",
    "    if fg_aps.shape[1]==3:\n",
    "        knee_freq, knee_tau = echo_utils.convert_knee_val(fg_aps[:,1],fg_aps[:,2])\n",
    "        knee = fg_aps[:,1]\n",
    "    else:\n",
    "        knee_tau = np.zeros_like(fg_aps[:,0])\n",
    "        knee = np.zeros_like(fg_aps[:,0])\n",
    "    \n",
    "    df_data = np.vstack((fg_aps[:,-1], knee, knee_tau, np.log10(knee_tau), fg_err, fg_r2s)).T\n",
    "    s_spl = s.split('_')\n",
    "    patient, cond, pharm, session_id = s_spl[7], s_spl[1], s_spl[2], session_dict[s_spl[3]]\n",
    "    chan = np.arange(len(fg_err))+1\n",
    "    df_cur = pd.DataFrame(np.hstack((np.repeat(np.array([patient,cond,pharm, session_id])[:,None].T, len(fg_err), axis=0), chan[:,None], df_data))\n",
    "                 ,columns=col_names)\n",
    "    df_cur.insert(5,'y', ctx_loc[0 if patient is 'Chibi' else 1][:,0])\n",
    "    df_cur.insert(6,'z', ctx_loc[0 if patient is 'Chibi' else 1][:,1])\n",
    "\n",
    "    df_combined = df_combined.append(df_cur, ignore_index=True)\n",
    "\n",
    "df_combined.columns\n",
    "df_combined = df_combined.astype({c:str if c in ['patient', 'cond', 'pharm'] else np.float for c in col_names})\n",
    "\n",
    "# saveout\n",
    "df_combined.to_csv(df_savepath+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Human ECoG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'AgeAtTimeOfStudy', 'ChannelName', 'ChannelPosition', 'ChannelRegion', 'ChannelType', 'Data', 'FacesLeft', 'FacesRight', 'Gender', 'Hemisphere', 'NodesLeft', 'NodesLeftInflated', 'NodesRegionLeft', 'NodesRegionRight', 'NodesRight', 'NodesRightInflated', 'Patient', 'RegionName', 'SamplingFrequency'])\n",
      "Loading file: /Users/rdgao/Documents/code/research/field-echos/results/MNI_rest//psd/1sec/fooof/psd_med/\n",
      "Total electrodes: 1772\n",
      "Total electrodes after dropping nans: 1722\n",
      "Total patients: 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../echo_utils.py:63: RuntimeWarning: invalid value encountered in power\n",
      "  knee_freq = knee**(1./exponent)\n",
      "/Users/rdgao/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: RuntimeWarning: invalid value encountered in less\n"
     ]
    }
   ],
   "source": [
    "thresh_knee_freq = 1.5\n",
    "    \n",
    "# load the various data variables, elec loc, etc\n",
    "basepath = '/Users/rdgao/Documents/data/MNI_rest/'\n",
    "datafile = basepath + 'WakefulnessMatlabFile.mat'\n",
    "result_basepath = '/Users/rdgao/Documents/code/research/field-echos/results/MNI_rest/'\n",
    "df_savepath = '../data/df_human'\n",
    "\n",
    "data_dict = io.loadmat(datafile, squeeze_me = True) # data file that has all the meta info\n",
    "region_labels = pd.read_csv(basepath+'/WakefulnessInformation/RegionInformation.csv') # channel labels\n",
    "patient_info = pd.read_csv(basepath+'/WakefulnessInformation/PatientInformation.csv', index_col=0, names=['gender', 'age'], skiprows=1) # patient labels\n",
    "region_labels['Region name']=[rl[1:-1] for rl in region_labels['Region name']] # get rid of quotes\n",
    "print(data_dict.keys())\n",
    "\n",
    "# load fooof results, use same glboal settings as monkey ECoG\n",
    "fooof_folder = result_basepath+'/psd/'+win_len+'/fooof/'+p_cur+'/'\n",
    "print('Loading file: %s'%fooof_folder)\n",
    "ff_list = [ff for ff in os.listdir(fooof_folder) if '.json' in ff]\n",
    "ff_file = ff_list[np.where([fg_param_to_load in f for f in ff_list])[0][0]] # load specific fooof file\n",
    "\n",
    "# return fooof fits and convert knee to tau\n",
    "fg_aps, fg_pks, fg_err, fg_r2s = echo_utils.return_fg_fits(ff_file, fooof_folder)\n",
    "if fg_aps.shape[1]==3:\n",
    "    knee_freq, knee_tau = echo_utils.convert_knee_val(fg_aps[:,1],fg_aps[:,2])\n",
    "    knee = fg_aps[:,1]\n",
    "    \n",
    "    # drop where knee_freq is less than 1Hz because the fit ends at 1Hz\n",
    "    knee_tau[knee_freq<thresh_knee_freq]=np.nan\n",
    "    \n",
    "else:\n",
    "    knee_tau = np.zeros_like(fg_aps[:,0])\n",
    "    knee = np.zeros_like(fg_aps[:,0])\n",
    "\n",
    "# create pandas df and throw everything in there\n",
    "e_type = np.array(data_dict['ChannelType'], 'c').view(np.uint8)-64.\n",
    "#patient_info['gender'] = 0 if 'M' else 1\n",
    "patient_info.replace(['M','F'], [0,1], inplace=True)\n",
    "df_info = np.vstack((data_dict['Patient'], \n",
    "                     patient_info.loc[data_dict['Patient']][['gender', 'age']].values.astype(int).T, \n",
    "                     e_type, \n",
    "                     data_dict['ChannelPosition'].T, \n",
    "                     data_dict['ChannelRegion'])\n",
    "                   ).T\n",
    "df_data = np.vstack((fg_aps[:,-1], knee_freq, knee_tau, np.log10(knee_tau), fg_err, fg_r2s)).T\n",
    "df_combined = pd.DataFrame(np.hstack((df_info,df_data)),columns=['patient','gender','age','etype', 'x','y','z','region','exp', 'knee_freq', 'tau','log_tau','err', 'r2'])\n",
    "\n",
    "# insert column for x_positive (collapse across L-R axis)\n",
    "df_combined.insert(5, 'x_pos', np.abs(df_combined['x'].values))\n",
    "\n",
    "# insert lobe info\n",
    "df_combined.insert(8, 'lobe', 0)\n",
    "lobe_id = {val: ind for ind, val in enumerate(region_labels['Lobe'].unique())}\n",
    "for ind, region in enumerate(region_labels['Region #']):\n",
    "    df_combined.loc[df_combined['region']==region,'lobe'] = lobe_id[region_labels.loc[ind,'Lobe']]\n",
    "\n",
    "print('Total electrodes: %i'%len(df_combined))\n",
    "\n",
    "# drop nans\n",
    "df_combined.dropna(inplace=True)\n",
    "df_combined.reset_index(drop=True, inplace=True)\n",
    "print('Total electrodes after dropping nans: %i'%len(df_combined))\n",
    "\n",
    "## print some electrode type info and correlation\n",
    "# print(df_combined.groupby('etype').count()['patient'])\n",
    "# print(df_combined[['exp','knee','tau','log_tau', 'err', 'r2']].corr('spearman'))\n",
    "\n",
    "print('Total patients: %i'%len(df_combined['patient'].unique()))\n",
    "df_combined.to_csv(df_savepath+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save PSD plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_fits = False\n",
    "\n",
    "if plot_fits: plt.figure(figsize=(5,5))\n",
    "for win_len_iter in ['1sec', '5sec']:\n",
    "    for p_cur_iter in ['psd_mean', 'psd_med']:\n",
    "        # construct channel metainfo and behavioral table\n",
    "        psd_data = np.load(result_basepath+'/psd/'+win_len_iter+'/psds.npz')\n",
    "\n",
    "        # load fooof results\n",
    "        fooof_folder = result_basepath +'/psd/'+win_len_iter+'/fooof/'+p_cur_iter+'/'  \n",
    "        ff_list = [ff for ff in os.listdir(fooof_folder) if '.json' in ff]\n",
    "\n",
    "        # plot psds and all fits\n",
    "        if plot_fits:\n",
    "            fit_fig_path = utils.makedir(fooof_folder, '/plts/', False)\n",
    "            f_axis = psd_data['f_axis']\n",
    "            psds = psd_data[p_cur_iter].T\n",
    "            fg_labels = [f.split('.')[0][3:] for f in ff_list]\n",
    "            # grab fgs\n",
    "            fg_all=[]\n",
    "            for ff in ff_list:\n",
    "                fg_dummy = FOOOFGroup()\n",
    "                fg_dummy.load(fooof_folder+ff)\n",
    "                fg_all.append(fg_dummy)\n",
    "            # plot\n",
    "            for chan in range(psds.shape[0]):\n",
    "                utils.plot_psd_fits(f_axis, psds, chan, fg_all, fg_labels)\n",
    "                plt.title('Channel: %i - Region: %i'%(chan, data_dict['ChannelRegion'][chan]))\n",
    "                fig_name = '/chan%i_reg%i.png'%(chan, data_dict['ChannelRegion'][chan])\n",
    "                plt.savefig(fit_fig_path+fig_name)\n",
    "                plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Collecting T1w/T2w & gene expression data\n",
    "T1T2 and gene expression maps projected onto HCP-MMP parcellation are obtained using code from Rudy's repo: https://github.com/rudyvdbrink/Surface_projection\n",
    "\n",
    "I collect and convert them into dataframes and save as a csv to be included in the project code repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot insert label, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fc385b68c035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mthickness_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manat_basepath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'tvals.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgene_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mthickness_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Entrez_ID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mthickness_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'T1T2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mthickness_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/voytek/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   3494\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3495\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3496\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_duplicates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_duplicates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3498\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/voytek/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;31m# Should this be a different kind of error??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"cannot insert {item}, already exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot insert label, already exists"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entrez_ID</th>\n",
       "      <th>label</th>\n",
       "      <th>L_V1</th>\n",
       "      <th>L_MST</th>\n",
       "      <th>L_V6</th>\n",
       "      <th>L_V2</th>\n",
       "      <th>L_V3</th>\n",
       "      <th>L_V4</th>\n",
       "      <th>L_V8</th>\n",
       "      <th>L_4</th>\n",
       "      <th>...</th>\n",
       "      <th>R_p47r</th>\n",
       "      <th>R_TGv</th>\n",
       "      <th>R_MBelt</th>\n",
       "      <th>R_LBelt</th>\n",
       "      <th>R_A4</th>\n",
       "      <th>R_STSva</th>\n",
       "      <th>R_TE1m</th>\n",
       "      <th>R_PI</th>\n",
       "      <th>R_a32pr</th>\n",
       "      <th>R_p24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>thickness</td>\n",
       "      <td>1.9801</td>\n",
       "      <td>2.4648</td>\n",
       "      <td>2.172</td>\n",
       "      <td>2.0203</td>\n",
       "      <td>2.2183</td>\n",
       "      <td>2.3595</td>\n",
       "      <td>2.6884</td>\n",
       "      <td>2.7759</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5275</td>\n",
       "      <td>3.2128</td>\n",
       "      <td>2.6487</td>\n",
       "      <td>2.5723</td>\n",
       "      <td>2.8997</td>\n",
       "      <td>2.8917</td>\n",
       "      <td>2.9095</td>\n",
       "      <td>2.6318</td>\n",
       "      <td>3.0857</td>\n",
       "      <td>3.2241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 362 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Entrez_ID      label    L_V1   L_MST   L_V6    L_V2    L_V3    L_V4  \\\n",
       "0        NaN  thickness  1.9801  2.4648  2.172  2.0203  2.2183  2.3595   \n",
       "\n",
       "     L_V8     L_4  ...  R_p47r   R_TGv  R_MBelt  R_LBelt    R_A4  R_STSva  \\\n",
       "0  2.6884  2.7759  ...  2.5275  3.2128   2.6487   2.5723  2.8997   2.8917   \n",
       "\n",
       "   R_TE1m    R_PI  R_a32pr   R_p24  \n",
       "0  2.9095  2.6318   3.0857  3.2241  \n",
       "\n",
       "[1 rows x 362 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_data = pd.read_csv(anat_basepath+'Glasser_data.csv')\n",
    "myelin_data = pd.read_csv(anat_basepath+'mvals.txt', header=None, names=gene_data.columns[1:])\n",
    "myelin_data.insert(0, 'Entrez_ID', np.nan)\n",
    "myelin_data.insert(1, 'label', 'T1T2')\n",
    "myelin_data\n",
    "\n",
    "thickness_data = pd.read_csv(anat_basepath+'tvals.txt', header=None, names=gene_data.columns[1:])\n",
    "thickness_data.insert(0, 'Entrez_ID', np.nan)\n",
    "thickness_data.insert(1, 'label', 'thickness')\n",
    "thickness_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nibabel as ni\n",
    "# annot_file = '/Users/rdgao/mne_data/MNE-sample-data/subjects/fsaverage/label/lh.HCPMMP1.annot'\n",
    "# mmp_labels, ctab, mmp_names = ni.freesurfer.read_annot(annot_file)\n",
    "# region_names = [n[2:-4].decode(\"utf-8\") for n in mmp_names[1:]]\n",
    "\n",
    "anat_basepath = '/Users/rdgao/Documents/data/GeneMyelin/genome_maps/'\n",
    "df_savepath = '../data/df_structural'\n",
    "\n",
    "gene_data = pd.read_csv(anat_basepath+'Glasser_data.csv')\n",
    "gene_meta = pd.read_csv(anat_basepath+'Homo_sapiens.csv')[['GeneID', 'Symbol']]\n",
    "\n",
    "# myelin map\n",
    "myelin_data = pd.read_csv(anat_basepath+'mvals.txt', header=None, names=gene_data.columns[1:])\n",
    "myelin_data.insert(0, 'Entrez_ID', np.nan)\n",
    "myelin_data.insert(1, 'label', 'T1T2')\n",
    "\n",
    "# thickness map\n",
    "thickness_data = pd.read_csv(anat_basepath+'tvals.txt', header=None, names=gene_data.columns[1:])\n",
    "thickness_data.insert(0, 'Entrez_ID', np.nan)\n",
    "thickness_data.insert(1, 'label', 'thickness')\n",
    "\n",
    "# Homo_sapiens.csv has the updated gene list, which excludes some of the Entrez IDs in Glasser_data.csv since \n",
    "# the publication of Gryglewski et al. 2018, so I prune them here and align labels and data into the same df.\n",
    "gene_labels = ['' for i in range(len(gene_data))]\n",
    "g_ids = gene_data['Entrez_ID'].tolist()\n",
    "for i_r, row in gene_meta.iterrows():\n",
    "    gene_labels[g_ids.index(row['GeneID'])] = row['Symbol']\n",
    "\n",
    "# insert label into gene data df\n",
    "gene_data.insert(1, 'label', gene_labels)\n",
    "# drop rows where Entrez_ID was not found in the metadata\n",
    "gene_data = gene_data.drop(index=np.where(gene_data['label']=='')[0])\n",
    "# combine dataframes\n",
    "df_struct = pd.concat((myelin_data, thickness_data, gene_data), ignore_index=True)\n",
    "df_struct.set_index('label', inplace=True)\n",
    "\n",
    "# save combined to csv\n",
    "df_struct.to_csv(anat_basepath+'struct_full.csv')\n",
    "\n",
    "# drop entrez ID column for ease of operation after\n",
    "df_struct.drop('Entrez_ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the gene ID to symbol conversion table because GOATOOLS will require it later\n",
    "gene_meta = pd.read_csv(anat_basepath+'Homo_sapiens.csv')[['GeneID', 'Symbol', 'Synonyms']]\n",
    "gene_meta.to_csv('../data/df_human_geneinfo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# check consistency of labeling between L & R hemisphere, and compute correlation\n",
    "regions_L = [l[2:] for l in df_struct.columns[0:180]]\n",
    "regions_R = [l[2:] for l in df_struct.columns[180:]]\n",
    "print(regions_L==regions_R)\n",
    "LR_corr = [pearsonr(row[0:180], row[180:])[0] for i_r, row in df_struct.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "plt.hist(LR_corr, 50)\n",
    "plt.xlabel('L-R Pearson Corr.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, correlation is pretty high between L and R hemisphere, but not as close to 1 as I expected. Could use L or R, or hemisphere average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save out but transpose so columns are features\n",
    "arr_struct = df_struct.values\n",
    "df_struct_L = pd.DataFrame(arr_struct[:,:180], index=df_struct.index, columns=regions_L).T\n",
    "df_struct_L.to_csv(df_savepath+'_L.csv')\n",
    "df_struct_R = pd.DataFrame(arr_struct[:,180:], index=df_struct.index, columns=regions_R).T\n",
    "df_struct_R.to_csv(df_savepath+'_R.csv')\n",
    "df_struct_avg = pd.DataFrame((arr_struct[:,:180]+arr_struct[:,180:])/2, index=df_struct.index, columns=regions_L).T\n",
    "df_struct_avg.to_csv(df_savepath+'_avg.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Aligning ECoG (MNI) and Structural (Glasser) data\n",
    "The ECoG electrode locations are given in (volumetric) MNI space, where as the myelination & expression data are given for surface Glasser parcellation. To compare the two datasets, and in general visualizing the ECoG data spatially, we have to align them to the same space.\n",
    "\n",
    "This can be done either through discrete assignments (1-to-1 or N-to-1), or upsampling into a common space and then smooth & aggregate back into either MNI or Glasser space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "MMP_data = nib.load(anat_basepath+'MMP 1.0 MNI projections/MMP_in_MNI_symmetrical_1.nii.gz')\n",
    "\n",
    "# since only <4% of voxels actually have non-zero parcellation values\n",
    "# we can reduce the map first and just search in the non-zero regions\n",
    "# reduce the map and find the indices where parcel value is non-zero\n",
    "MMP_map = np.asarray(MMP_data.get_data())\n",
    "MMP_sparse_coords = np.array(np.where(MMP_map>0)).T\n",
    "MMP_map_sparse_flat = MMP_map[np.where(MMP_map>0)]\n",
    "\n",
    "# r_search = 3\n",
    "# # transform to MMP indices\n",
    "# ecog_coors_transformed = np.array([echo_utils.apply_affine(MMP_data.affine, row[['x','y','z']].values, False) for r_i, row in df_combined.iterrows()])\n",
    "\n",
    "# # find the closest projection of ecog onto parcellation voxels within a radius\n",
    "# proj_dist_inds = echo_utils.project_ecog_mmp(ecog_coors_transformed, MMP_sparse_coords, r_search, find_nearest=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsample, Smoothing & Project to MMP\n",
    "Here, we create a electrode distance-weighted map for each subject that's a function of a Gaussian where the weight drops to 50% at distance d. The weight is computed at every MNI-coordinate value at which there is an MMP parcel. The distance-weighted feature matrix (in this case, tau) is then computed as a weighted sum over all electrodes and grouped at the parcel level. This has two advantages: 1) electrodes near parcellation boundaries still contribute to the nearby parcels even if it doesn't fall within it, and 2) electrodes in the center of a parcellation contribute more to the parcel's value than electrodes at boundaries. \n",
    "\n",
    "W_sum and W_max record the sum and max of the weight within each parcel for every subject, as a measure of confidence of the largest contribution (how close the closest electrode is) that fell within the parcel.\n",
    "\n",
    "Original MATLAB code & idea for spatial smoothing with Gaussian courtesy of discussion with Thomas Pfeffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1|2|3|4|5|6|7|8|9|10|11|"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rdgao/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/Users/rdgao/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12|13|14|15|16|17|18|19|20|21|22|23|24|25|26|27|28|29|30|31|32|33|34|35|36|37|38|39|40|41|42|43|44|45|46|47|48|49|50|52|53|54|55|56|57|58|59|60|61|62|63|64|65|66|67|68|69|70|71|72|73|74|75|76|77|78|79|80|81|82|83|84|85|87|88|89|90|91|92|93|94|96|97|98|99|100|101|102|103|104|106|107|108|109|110|"
     ]
    }
   ],
   "source": [
    "df_combined = pd.read_csv('../data/df_human.csv', index_col=0)\n",
    "\n",
    "# set smoothing parameter: Gaussian is at 50% when d voxels away\n",
    "d = 4\n",
    "d_alpha= d/(-np.log(0.5))**0.5\n",
    "\n",
    "output_grid = MMP_sparse_coords\n",
    "feature = 'tau'\n",
    "feat_weighted, W_sum, W_max = [],[],[]\n",
    "for i_p in np.unique(df_combined['patient']):\n",
    "    # iterate over patients\n",
    "    print(int(i_p), end='|')\n",
    "    df_patient = df_combined[df_combined['patient']==i_p]\n",
    "    \n",
    "    # get transformed ECoG coordinate\n",
    "    input_grid = np.array([echo_utils.apply_affine(MMP_data.affine, row[['x','y','z']].values, False) for r_i, row in df_patient.iterrows()])    \n",
    "\n",
    "    # create the weight matrix from input to output projection based on Gaussian weighting of Euclidean distance\n",
    "    W_mat = np.zeros((input_grid.shape[0],output_grid.shape[0]))\n",
    "    for ig in range(input_grid.shape[0]):\n",
    "        W_mat[ig,:] = np.exp(-np.linalg.norm(output_grid-input_grid[ig,:], axis=1)**2/d_alpha**2)\n",
    "\n",
    "    # get total and max weights to drop bad coverage points\n",
    "    W_sum.append(W_mat.sum(0)) \n",
    "    W_max.append(np.max(W_mat,0))\n",
    "    feat_weighted.append(np.dot(df_patient[feature].values, W_mat)/W_mat.sum(0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# save parcellated feature matrix\n",
    "df_save = pd.DataFrame(np.array(feat_weighted).T, columns=np.unique(df_combined['patient']).astype(int))\n",
    "df_save.insert(0, 'parcel', MMP_map_sparse_flat)\n",
    "df_save.groupby('parcel').mean().T.to_csv('../data/df_human_%s_weighted_%i.csv'%(feature, d), header=region_names)\n",
    "\n",
    "# save parcellated weight matrix sum\n",
    "df_save = pd.DataFrame(np.array(W_sum).T, columns=np.unique(df_combined['patient']).astype(int))\n",
    "df_save.insert(0, 'parcel', MMP_map_sparse_flat)\n",
    "df_save.groupby('parcel').sum().T.to_csv('../data/df_human_W_sum_%i.csv'%d, header=region_names)\n",
    "\n",
    "# save parcellated weight matrix max\n",
    "df_save = pd.DataFrame(np.array(W_max).T, columns=np.unique(df_combined['patient']).astype(int))\n",
    "df_save.insert(0, 'parcel', MMP_map_sparse_flat)\n",
    "df_save = df_save.groupby('parcel').max().T.to_csv('../data/df_human_W_max_%i.csv'%d, header=region_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab brain-specfic genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mygene for parsing ENSEMBL to entrez \n",
    "# https://pypi.org/project/mygene/\n",
    "\n",
    "# how do I cite this??\n",
    "import mygene\n",
    "mg = mygene.MyGeneInfo()\n",
    "\n",
    "# table from Fagerberg et al. 2014: https://www.mcponline.org/content/13/2/397.long\n",
    "df_gene_body = pd.read_excel('../data/mcp.M113.035600-2.xlsx', index_col=0) \n",
    "\n",
    "#last column is category note\n",
    "df_gene_body = df_gene_body[df_gene_body.columns[:-1]]\n",
    "\n",
    "# genes expressed 4X greater in the brain than the median across all genes are considered \"brain genes\"\n",
    "# same as done in Burt 2018, where they follow Genovese et al. 2016: https://www.nature.com/articles/nn.4402\n",
    "brain_genes = df_gene_body[df_gene_body['brain']>df_gene_body.median(axis=1)*4].index.to_list()\n",
    "\n",
    "# query\n",
    "brain_genes_id = [mg.getgene(g, ['_id', 'symbol']) for g in brain_genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brain_genes = pd.DataFrame([[g['_id'], g['symbol']] for g in brain_genes_id if g is not None], columns=['GeneID', 'symbol'])\n",
    "\n",
    "# drop columns where no Entrez ID is found and save out\n",
    "df_brain_genes[~df_brain_genes['GeneID'].str.contains(\"ENS\")].to_csv('../data/df_brain_genes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
